{"name":"Cassandra","tagline":"A Puppet module to install and manage Apache Cassandra.","body":"# cassandra\r\n\r\n#### Table of Contents\r\n\r\n1. [Overview](#overview)\r\n2. [Setup - The basics of getting started with cassandra](#setup)\r\n    * [What cassandra affects](#what-cassandra-affects)\r\n    * [Beginning with cassandra](#beginning-with-cassandra)\r\n    * [Upgrading](#upgrading)\r\n3. [Usage - Configuration options and additional functionality](#usage)\r\n4. [Reference - An under-the-hood peek at what the module is doing and how](#reference)\r\n5. [Limitations - OS compatibility, etc.](#limitations)\r\n6. [Contributers](#contributers)\r\n7. [External Links](#external-links)\r\n\r\n## Overview\r\n\r\nThis module installs and configures Apache Cassandra.  The installation steps\r\nwere taken from the installation documentation prepared by DataStax [1] and\r\nthe configuration parameters are the same as those for the Puppet module\r\ndeveloped by msimonin [2].\r\n\r\n## Setup\r\n\r\n### What cassandra affects\r\n\r\n* Installs the Cassandra package (default **dsc21**).\r\n* Configures settings in *${config_path}/cassandra.yaml*.\r\n* Optionally insures that the Cassandra service is enabled and running.\r\n* Optionally installs the Cassandra support tools (e.g. cassandra21-tools).\r\n* Optionally configures a Yum repository to install the Cassandra packages\r\n  from (on RedHat).\r\n* Optionally configures an Apt repository to install the Cassandra packages\r\n  from (on Ubuntu).\r\n* Optionally installs a JRE/JDK package (e.g. java-1.7.0-openjdk).\r\n* Optionally installs the DataStax agent.\r\n\r\n### Beginning with cassandra\r\n\r\nThis most basic example would attempt to install the default Cassandra package\r\n(assuming there is an available repository).  See the *Usage*(#usage) section\r\nfor more realistic scenarios.\r\n\r\n```puppet\r\nnode 'example' {\r\n  include '::cassandra'\r\n}\r\n```\r\n\r\nTo install the DataStax agent, include the specific class.\r\n\r\n```puppet\r\nnode 'example' {\r\n  include '::cassandra'\r\n  include '::cassandra::datastax_agent'\r\n}\r\n```\r\n\r\nTo install with a reasonably sensible Java environment include the java\r\nsubclass.\r\n\r\n```puppet\r\nnode 'example' {\r\n  include '::cassandra'\r\n  include '::cassandra::java'\r\n}\r\n```\r\n\r\nTo install Cassandra with the optional utilities.\r\n\r\n```puppet\r\nnode 'example' {\r\n  include '::cassandra'\r\n  include '::cassandra::optutils'\r\n}\r\n```\r\n\r\nTo install the main cassandra package (which is mandatory) and all the\r\noptional packages, do the following:\r\n\r\n```puppet\r\nnode 'example' {\r\n  include '::cassandra'\r\n  include '::cassandra::datastax_agent'\r\n  include '::cassandra::java'\r\n  include '::cassandra::optutils'\r\n}\r\n```\r\n\r\nBy saying the cassandra class/package is mandatory, what is meant is that all\r\nthe sub classes have a dependancy on the main class.  So for example one\r\ncould not specify the cassandra::java class for a node with the cassandra\r\nclass also being included.\r\n\r\n### Upgrading\r\n\r\nThe following changes to the API have taken place.\r\n\r\n**Changes in 0.4.0**\r\n\r\n* cassandra::datastax_agent_package_ensure has now been replaced with\r\n  cassandra::datastax_agent::package_ensure.\r\n* cassandra::datastax_agent_service_enable has now been replaced with\r\n  cassandra::datastax_agent::service_enable.\r\n* cassandra::datastax_agent_service_ensure has now been replaced with\r\n  cassandra::datastax_agent::service_ensure.\r\n* cassandra::datastax_agent_package_name has now been replaced with\r\n  cassandra::datastax_agent::package_name.\r\n* cassandra::datastax_agent_service_name has now been replaced with\r\n  cassandra::datastax_agent::service_name.\r\n\r\n* cassandra::java_package_ensure has now been replaced with\r\n  cassandra::java::ensure.\r\n* cassandra::java_package_name has now been replaced with\r\n  cassandra::java::package_name.\r\n\r\n* cassandra::cassandra_opt_package_ensure has now been replaced with\r\n  cassandra::optutils:ensure.\r\n* cassandra::cassandra_opt_package_name has now been replaced with\r\n  cassandra::optutils:package_name.\r\n\r\n**Changes in 0.3.0**\r\n\r\n* cassandra_opt_package_ensure changed from 'present' to undef.\r\n\r\n* The manage_service option has been replaced with service_enable and\r\n  service_ensure.\r\n\r\n## Usage\r\n\r\nTo install Cassandra in a two node cluster called 'Foobar Cluster' where\r\nnode1 (192.168.42.1) is the seed and node2 192.168.42.2 is also to be a\r\nmember, do something similar to this:\r\n\r\n```puppet\r\ninclude cassandra::java\r\ninclude cassandra::optutils\r\n\r\nnode 'node1' {\r\n  class { 'cassandra':\r\n    cluster_name    => 'Foobar Cluster',\r\n    listen_address  => \"${::ipaddress}\",\r\n    seeds           => \"${::ipaddress}\",\r\n    manage_dsc_repo => true\r\n  }\r\n}\r\n\r\nnode 'node2' {\r\n  class { 'cassandra':\r\n    cluster_name    => 'Foobar Cluster',\r\n    listen_address  => \"${::ipaddress}\",\r\n    seeds           => '192.168.42.1',\r\n    manage_dsc_repo => true\r\n  }\r\n}\r\n```\r\n\r\nThis would also ensure that the JDK is installed and the optional Cassandra\r\ntools.\r\n\r\n### Class: cassandra\r\n\r\n#### Parameters\r\n\r\n#####`authenticator`\r\nAuthentication backend, implementing IAuthenticator; used to identify users\r\nOut of the box, Cassandra provides\r\norg.apache.cassandra.auth.{AllowAllAuthenticator, PasswordAuthenticator}.\r\n\r\n* AllowAllAuthenticator performs no checks - set it to disable authentication.\r\n* PasswordAuthenticator relies on username/password pairs to authenticate\r\n  users. It keeps usernames and hashed passwords in system_auth.credentials\r\n  table. Please increase system_auth keyspace replication factor if you use this\r\n  authenticator.\r\n\r\nDefault: **AllowAllAuthenticator**\r\n\r\n#####`authorizer`\r\nAuthorization backend, implementing IAuthorizer; used to limit access/provide\r\npermissions Out of the box, Cassandra provides\r\norg.apache.cassandra.auth.{AllowAllAuthorizer, CassandraAuthorizer}.\r\n\r\n* AllowAllAuthorizer allows any action to any user - set it to disable\r\n  authorization.\r\n* CassandraAuthorizer stores permissions in system_auth.permissions table.\r\n  Please increase system_auth keyspace replication factor if you use this\r\n  authorizer.\r\n\r\nDefault: **AllowAllAuthorizer**\r\n\r\n#####`auto_snapshot`\r\nWhether or not a snapshot is taken of the data before keyspace truncation\r\nor dropping of column families. The STRONGLY advised default of true \r\nshould be used to provide data safety. If you set this flag to false, you will\r\nlose data on truncation or drop (default **true**).\r\n\r\n#####`cassandra_opt_package_ensure`\r\nThe status of the package specified in **cassandra_opt_package_name**.  Can be\r\n*present*, *latest* or a specific version number.  If\r\n*cassandra_opt_package_name* is *undef*, this option has no effect (default\r\n**present**).\r\n\r\n#####`cassandra_opt_package_name`\r\nIf left at the default, this will change to 'cassandra21-tools' on RedHat\r\nor 'cassandra-tools' on Ubuntu.  Alternatively this use can specify the\r\npackage name\r\n(default undef).\r\n\r\n#####`cassandra_package_ensure`\r\nThe status of the package specified in **cassandra_package_name**.  Can be\r\n*present*, *latest* or a specific version number (default **present**).\r\n\r\n#####`cassandra_package_name`\r\nThe name of the Cassandra package.  Must be installable from a repository\r\n(default **dsc21**).\r\n\r\n#####`cassandra_yaml_tmpl`\r\nThe path to the Puppet template for the Cassandra configuration file.  This\r\nallows the user to supply their own customized template.  A Cassandra 1.X\r\ncompatible template called cassandra1.yaml.erb has been provided by @Spredzy\r\n(default **cassandra/cassandra.yaml.erb**).\r\n\r\n#####`client_encryption_enabled`\r\nEnable or disable client/server encryption (default **false**).\r\n\r\n#####`client_encryption_keystore`\r\nKeystore for client_encryption (default **conf/.keystore**).\r\n\r\n#####`client_encryption_keystore_password`\r\nKeystore password for client encryption (default **cassandra**).\r\n\r\n#####`cluster_name`\r\nThe name of the cluster. This is mainly used to prevent machines in one logical\r\ncluster from joining another (default **Test Cluster**).\r\n\r\n#####`commitlog_directory`\r\nCommit log.  when running on magnetic HDD, this should be a separate spindle\r\nthan the data directories (default **/var/lib/cassandra/commitlog**).\r\n\r\n#####`concurrent_counter_writes`\r\nFor workloads with more data than can fit in memory, Cassandra's bottleneck\r\nwill be reads that need to fetch data from disk. \"concurrent_reads\"\r\nshould be set to (16 * number_of_drives) in order to allow the operations to\r\nenqueue low enough in the stack that the OS and drives can reorder them. Same\r\napplies to \"concurrent_counter_writes\", since counter writes read the current\r\nvalues before incrementing and writing them back.\r\n\r\nOn the other hand, since writes are almost never IO bound, the ideal\r\nnumber of \"concurrent_writes\" is dependent on the number of cores in\r\nyour system; (8 * number_of_cores) is a good rule of thumb (default **32**).\r\n\r\n#####`concurrent_reads`\r\nFor workloads with more data than can fit in memory, Cassandra's bottleneck\r\nwill be reads that need to fetch data from disk. \"concurrent_reads\"\r\nshould be set to (16 * number_of_drives) in order to allow the operations to\r\nenqueue low enough in the stack that the OS and drives can reorder them. Same\r\napplies to \"concurrent_counter_writes\", since counter writes read the current\r\nvalues before incrementing and writing them back.\r\n\r\nOn the other hand, since writes are almost never IO bound, the ideal\r\nnumber of \"concurrent_writes\" is dependent on the number of cores in\r\nyour system; (8 * number_of_cores) is a good rule of thumb (default **32**).\r\n\r\n#####`concurrent_writes`\r\nFor workloads with more data than can fit in memory, Cassandra's bottleneck\r\nwill be reads that need to fetch data from disk. \"concurrent_reads\"\r\nshould be set to (16 * number_of_drives) in order to allow the operations to\r\nenqueue low enough in the stack that the OS and drives can reorder them. Same\r\napplies to \"concurrent_counter_writes\", since counter writes read the current\r\nvalues before incrementing and writing them back.\r\n\r\nOn the other hand, since writes are almost never IO bound, the ideal\r\nnumber of \"concurrent_writes\" is dependent on the number of cores in\r\nyour system; (8 * number_of_cores) is a good rule of thumb (default **32**).\r\n\r\n#####`config_path`\r\nThe path to the cassandra configuration file.  If this is undef, it will be\r\nchanged to /etc/cassandra/default.conf on the RedHat family of operating\r\nsystems or /etc/cassandra on Ubuntu.  Otherwise the user can specify the\r\npath name\r\n(default **undef**).\r\n\r\n#####`data_file_directories`\r\nDirectories where Cassandra should store data on disk.  Cassandra\r\nwill spread data evenly across them, subject to the granularity of\r\nthe configured compaction strategy (default **['/var/lib/cassandra/data']**).\r\n\r\n#####`disk_failure_policy`\r\nPolicy for data disk failures:\r\n\r\n* die: shut down gossip and Thrift and kill the JVM for any fs errors or\r\n  single-sstable errors, so the node can be replaced.\r\n* stop_paranoid: shut down gossip and Thrift even for single-sstable errors.\r\n* stop: shut down gossip and Thrift, leaving the node effectively dead, but\r\n  can still be inspected via JMX.\r\n* best_effort: stop using the failed disk and respond to requests based on\r\n  remaining available sstables.  This means you WILL see obsolete\r\n  data at CL.ONE!\r\n* ignore: ignore fatal errors and let requests fail, as in pre-1.2 Cassandra.\r\n\r\nDefault: **stop**\r\n\r\n#####`endpoint_snitch`\r\nSet this to a class that implements IEndpointSnitch.  The snitch has two\r\nfunctions:\r\n\r\n* it teaches Cassandra enough about your network topology to route\r\n  requests efficiently.\r\n* it allows Cassandra to spread replicas around your cluster to avoid\r\n  correlated failures. It does this by grouping machines into\r\n  \"datacenters\" and \"racks.\"  Cassandra will do its best not to have\r\n  more than one replica on the same \"rack\" (which may not actually\r\n  be a physical location).\r\n\r\nIF YOU CHANGE THE SNITCH AFTER DATA IS INSERTED INTO THE CLUSTER,\r\nYOU MUST RUN A FULL REPAIR, SINCE THE SNITCH AFFECTS WHERE REPLICAS\r\nARE PLACED.\r\n\r\nOut of the box, Cassandra provides:\r\n\r\n* SimpleSnitch: Treats Strategy order as proximity. This can improve cache\r\n  locality when disabling read repair.  Only appropriate for\r\n  single-datacenter deployments.\r\n* GossipingPropertyFileSnitch: This should be your go-to snitch for production\r\n  use.  The rack and datacenter for the local node are defined in\r\n  cassandra-rackdc.properties and propagated to other nodes via\r\n  gossip.  If cassandra-topology.properties exists, it is used as a\r\n  fallback, allowing migration from the PropertyFileSnitch.\r\n* PropertyFileSnitch: Proximity is determined by rack and data center, which are\r\n  explicitly configured in cassandra-topology.properties.\r\n* Ec2Snitch: Appropriate for EC2 deployments in a single Region. Loads Region\r\n  and Availability Zone information from the EC2 API. The Region is\r\n  treated as the datacenter, and the Availability Zone as the rack.\r\n  Only private IPs are used, so this will not work across multiple Regions.\r\n* Ec2MultiRegionSnitch: Uses public IPs as broadcast_address to allow\r\n  cross-region connectivity.  (Thus, you should set seed addresses to the public\r\n  IP as well.) You will need to open the storage_port or\r\n  ssl_storage_port on the public IP firewall.  (For intra-Region\r\n  traffic, Cassandra will switch to the private IP after\r\n  establishing a connection.)\r\n* RackInferringSnitch: Proximity is determined by rack and data center, which\r\n  are assumed to correspond to the 3rd and 2nd octet of each node's IP\r\n  address, respectively.  Unless this happens to match your\r\n  deployment conventions, this is best used as an example of\r\n  writing a custom Snitch class and is provided in that spirit.\r\n\r\nYou can use a custom Snitch by setting this to the full class name\r\nof the snitch, which will be assumed to be on your classpath.\r\n\r\nDefault: **SimpleSnitch**\r\n\r\n#####`hinted_handoff_enabled`\r\nSee http://wiki.apache.org/cassandra/HintedHandoff May either be \"true\" or\r\n\"false\" to enable globally, or contain a list of data centers to enable\r\nper-datacenter (e.g. 'DC1,DC2').  Defaults to **'true'**.\r\n\r\n#####`incremental_backups`\r\nSet to true to have Cassandra create a hard link to each sstable\r\nflushed or streamed locally in a backups/ subdirectory of the\r\nkeyspace data.  Removing these links is the operator's\r\nresponsibility (default **false**).\r\n\r\n#####`internode_compression`\r\nControls whether traffic between nodes is compressed. Can be:\r\n\r\n* all  - all traffic is compressed\r\n* dc   - traffic between different datacenters is compressed\r\n* none - nothing is compressed.\r\n\r\nDefault **all**\r\n\r\n#####`listen_address`\r\nAddress or interface to bind to and tell other Cassandra nodes to connect to\r\n(default **localhost**).\r\n\r\n#####`manage_dsc_repo`\r\nIf set to true then a repository will be setup so that packages can be\r\ndownloaded from the DataStax community edition (default **false**).\r\n\r\n#####`native_transport_port`\r\nPort for the CQL native transport to listen for clients on\r\nFor security reasons, you should not expose this port to the internet.\r\nFirewall it if needed (default **9042**).\r\n\r\n#####`num_tokens`\r\nThis defines the number of tokens randomly assigned to this node on the ring\r\nThe more tokens, relative to other nodes, the larger the proportion of data\r\nthat this node will store. You probably want all nodes to have the same number\r\nof tokens assuming they have equal hardware capability.\r\n\r\n#####`partitioner`\r\nThe partitioner is responsible for distributing groups of rows (by\r\npartition key) across nodes in the cluster.  You should leave this\r\nalone for new clusters.  The partitioner can NOT be changed without\r\nreloading all data, so when upgrading you should set this to the\r\nsame partitioner you were already using.\r\n\r\nBesides Murmur3Partitioner, partitioners included for backwards\r\ncompatibility include RandomPartitioner, ByteOrderedPartitioner, and\r\nOrderPreservingPartitioner (default\r\n**org.apache.cassandra.dht.Murmur3Partitioner**)\r\n\r\n#####`rpc_address`\r\nThe address to bind the Thrift RPC service and native transport server to\r\n(default **localhost**).\r\n\r\n#####`rpc_port`\r\nPort for Thrift to listen for clients on (default **9160**).\r\n\r\n#####`rpc_server_type`\r\nCassandra provides two out-of-the-box options for the RPC Server:\r\n\r\n* One thread per thrift connection. For a very large number of clients,\r\n  memory will be your limiting factor. On a 64 bit JVM, 180KB is the minimum\r\n  stack size per thread, and that will correspond to your use of virtual memory\r\n  (but physical memory may be limited depending on use of stack space).\r\n* Stands for \"half synchronous, half asynchronous.\" All thrift clients\r\n  are handled asynchronously using a small number of threads that does\r\n  not vary with the amount of thrift clients (and thus scales well to many\r\n  clients).  The rpc requests are still synchronous (one thread per active\r\n  request). If hsha is selected then it is essential that rpc_max_threads\r\n  is changed from the default value of unlimited.\r\n\r\nThe default is sync because on Windows hsha is about 30% slower.  On Linux,\r\nsync/hsha performance is about the same, with hsha of course using less memory.\r\n\r\nAlternatively, you can provide your own RPC server by providing the\r\nfully-qualified class name of an o.a.c.t.TServerFactory that can create an\r\ninstance of it.\r\n\r\n#####`saved_caches_directory`\r\nDefault: **/var/lib/cassandra/saved_caches**\r\n\r\n#####`seeds`\r\nAddresses of hosts that are deemed contact points.  Cassandra nodes use this\r\nlist of hosts to find each other and learn the topology of the ring.  You must\r\nchange this if you are running multiple nodes!  Seeds is actually a\r\ncomma-delimited list of addresses (default **127.0.0.1**).\r\n\r\n#####`server_encryption_internode`\r\nEnable or disable inter-node encryption (default **none**).\r\n\r\n#####`server_encryption_keystore`\r\nDefault: **conf/.keystore**\r\n\r\n#####`server_encryption_keystore_password`\r\nDefault: **cassandra**\r\n\r\n#####`server_encryption_truststore`\r\nDefault: **conf/.truststore**\r\n\r\n#####`server_encryption_truststore_password`\r\nDefault: **cassandra**\r\n\r\n#####`service_enable`\r\nEnable the Cassandra service to start at boot time.  Valid values are true\r\nor false\r\n(default: **true**)\r\n\r\n#####`service_ensure`\r\nEnsure the Cassandra service is running.  Valid values are running or stopped\r\n(default: **running**)\r\n\r\n#####`service_name`\r\nThe name of the service that runs the Cassandra software (default\r\n**cassandra**).\r\n\r\n#####`snapshot_before_compaction`\r\nWhether or not to take a snapshot before each compaction.  Be\r\ncareful using this option, since Cassandra won't clean up the\r\nsnapshots for you.  Mostly useful if you're paranoid when there\r\nis a data format change (default **false**).\r\n\r\n#####`start_native_transport`\r\nWhether to start the native transport server.  Please note that the address on\r\nwhich the native transport is bound is the same as the rpc_address. The port\r\nhowever is different and specified below (default **true**).\r\n\r\n#####`start_rpc`\r\nWhether to start the thrift rpc server (default **true**).\r\n\r\n#####`storage_port`\r\nTCP port, for commands and data for security reasons, you should not expose this\r\nport to the internet.  Firewall it if needed (default **7000**).\r\n\r\n### Class: cassandra::datastax_agent\r\n\r\n####`package_ensure`\r\nIs passed to the package reference.  Valid values are **present** or a version\r\nnumber\r\n(default **present**).\r\n\r\n####`package_name`\r\nIs passed to the package reference (default **datastax-agent**).\r\n\r\n####`service_ensure`\r\nIs passed to the service reference (default **running**).\r\n\r\n####`service_enable`\r\nIs passed to the service reference (default **true**).\r\n\r\n####`service_name`\r\nIs passed to the service reference (default **datastax-agent**).\r\n\r\n####`stomp_interface`\r\nIf the value is changed from the default of *undef* then this is what is\r\nset as the stomp_interface setting in /var/lib/datastax-agent/conf/address.yaml\r\nwhich connects the agent to an OpsCenter instance\r\n(default **undef**).\r\n\r\n### Class: cassandra::java\r\n\r\n####`ensure`\r\nIs passed to the package reference.  Valid values are **present** or a version\r\nnumber\r\n(default **present**).\r\n\r\n####`package_name`\r\nIf the default value of *undef* is left as it is, then a package called\r\njava-1.8.0-openjdk-headless or openjdk-7-jre-headless will be installed\r\non a Red Hat family or Ubuntu system respectively.  Alternatively, one\r\ncan specify a package that is available in a package repository to the\r\nnode\r\n(default **undef**).\r\n\r\n### Class: cassandra::optutils\r\n\r\n####`ensure`\r\nIs passed to the package reference.  Valid values are **present** or a version\r\nnumber\r\n(default **present**).\r\n\r\n####`package_name`\r\nIf the default value of *undef* is left as it is, then a package called\r\ncassandra21-tools or cassandra-tools will be installed\r\non a Red Hat family or Ubuntu system respectively.  Alternatively, one\r\ncan specify a package that is available in a package repository to the\r\nnode\r\n(default **undef**).\r\n\r\n## Reference\r\n\r\nThis module uses the package type to install the Cassandra package, the\r\noptional Cassandra tools, the DataStax agent and Java package.\r\n\r\nIt optionally uses the service type to enable the cassandra service and/or the\r\nDataStax agent and ensure that they are running.\r\n\r\nIt also uses the yumrepo type on the RedHat family of operating systems to\r\n(optionally) install the *DataStax Repo for Apache Cassandra*.\r\n\r\nOn Ubuntu, the apt class is optionally utilised.\r\n\r\n## Limitations\r\n\r\nThis module currently still has somewhat limited functionality.  More\r\nparameters and configuration parameters will be added later.\r\n\r\nThere is currently no method for this module to manipulate Java options.\r\n\r\nCurrently the is no configuration or customisation of the DataStax Agent.\r\n\r\nTested on the RedHat family versions 6 and 7, Ubuntu 12.04 and 14.04, Puppet\r\n(CE) 3.7.5 and DSC 2.1.5.\r\n\r\n## Contributers\r\n\r\nContributions will be greatfully accepted.  Please go to the project page,\r\nfork the project, make your changes locally and then raise a pull request.\r\nDetails on how to do this are available at\r\nhttps://guides.github.com/activities/contributing-to-open-source.\r\n\r\n### Additional Contributers\r\n\r\nYanis Guenane (GitHub [@spredzy](https://github.com/Spredzy)) provided the\r\nCassandra 1.x compatible template\r\n(see [#11](https://github.com/locp/cassandra/pull/11)).\r\n\r\n## External Links\r\n\r\n[1] - *Installing DataStax Community on RHEL-based systems*, available at\r\nhttp://docs.datastax.com/en/cassandra/2.1/cassandra/install/installRHEL_t.html, accessed 25th May 2015.\r\n\r\n[2] - *msimonin/cassandra: Puppet module to install Apache Cassandra from\r\nthe DataStax distribution. Forked from gini/cassandra*, available at\r\nhttps://forge.puppetlabs.com/msimonin/cassandra, accessed 17th March 2015.\r\n","google":"UA-6773548-6","note":"Don't delete this file! It's used internally to help with page regeneration."}